{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHeCj3IYJ9WuJ5Wya0jseD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iliavrtn/final-project/blob/main/PDF_to_TXT_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We tests three popular libraries for this purpose: PyMuPDF (also known as fitz), pdfminer.six, and PyPDF2. These libraries vary in terms of ease of use, speed, and the fidelity of the conversion."
      ],
      "metadata": {
        "id": "DfqIHtDmCwX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Speed of Conversion - How fast each library processes the PDF documents.\n",
        "2. Accuracy and Fidelity - How accurately the text is extracted (including\n",
        "handling of special formatting or characters).\n",
        "3. Differences in Results - Any noticeable differences in the output text.\n",
        "\n"
      ],
      "metadata": {
        "id": "yrJfqht3C2Wb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfiM3t-pBs45",
        "outputId": "bc96a517-d6a3-4417-f695-342abbbd5b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF pdfminer.six PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Ie2oHVD7co",
        "outputId": "dad8a40f-541a-4634-acc9-66450a762bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.6 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Installing collected packages: PyPDF2, PyMuPDFb, PyMuPDF, pdfminer.six\n",
            "Successfully installed PyMuPDF-1.24.7 PyMuPDFb-1.24.6 PyPDF2-3.0.1 pdfminer.six-20240706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import fitz  # PyMuPDF\n",
        "from pdfminer.high_level import extract_text as pdfminer_extract_text\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "p-6AqAVHDMOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_with_pymupdf(file_path):\n",
        "    start = time.time()\n",
        "    doc = fitz.open(file_path)\n",
        "    text = ''\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    duration = time.time() - start\n",
        "    return text, duration\n",
        "\n",
        "def convert_with_pdfminer(file_path):\n",
        "    start = time.time()\n",
        "    text = pdfminer_extract_text(file_path)\n",
        "    duration = time.time() - start\n",
        "    return text, duration\n",
        "\n",
        "def convert_with_pypdf2(file_path):\n",
        "    start = time.time()\n",
        "    reader = PdfReader(file_path)\n",
        "    text = ''\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or ''\n",
        "    duration = time.time() - start\n",
        "    return text, duration\n",
        "\n",
        "def save_text(text, output_folder, filename):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    with open(os.path.join(output_folder, filename), 'w', encoding='utf-8') as file:\n",
        "        file.write(text)\n",
        "\n",
        "def process_files(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing: {filename}\")\n",
        "\n",
        "            # Convert with PyMuPDF\n",
        "            pymupdf_text, pymupdf_duration = convert_with_pymupdf(file_path)\n",
        "            save_text(pymupdf_text, os.path.join(folder_path, filename[:-4], 'PyMuPDF'), filename[:-4] + '.txt')\n",
        "            print(f\"PyMuPDF Time: {pymupdf_duration:.2f} seconds\")\n",
        "\n",
        "            # Convert with pdfminer.six\n",
        "            pdfminer_text, pdfminer_duration = convert_with_pdfminer(file_path)\n",
        "            save_text(pdfminer_text, os.path.join(folder_path, filename[:-4], 'PDFMiner'), filename[:-4] + '.txt')\n",
        "            print(f\"PDFMiner Time: {pdfminer_duration:.2f} seconds\")\n",
        "\n",
        "            # Convert with PyPDF2\n",
        "            pypdf2_text, pypdf2_duration = convert_with_pypdf2(file_path)\n",
        "            save_text(pypdf2_text, os.path.join(folder_path, filename[:-4], 'PyPDF2'), filename[:-4] + '.txt')\n",
        "            print(f\"PyPDF2 Time: {pypdf2_duration:.2f} seconds\")\n",
        "\n",
        "# Specify the path to your folder\n",
        "folder_path = '/content/drive/MyDrive/🅰 Aleph - Capstone Project 2024/PDF to TXT books TEST'\n",
        "process_files(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v8mdSlpDP35",
        "outputId": "39fa8cd4-c8bf-4a9a-f020-8d1c376d42c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: COPY_axiomatic-set-theory.pdf\n",
            "PyMuPDF Time: 2.95 seconds\n",
            "PDFMiner Time: 32.02 seconds\n",
            "PyPDF2 Time: 5.68 seconds\n",
            "Processing: COPY_abstract_set_theory.pdf\n",
            "PyMuPDF Time: 1.84 seconds\n",
            "PDFMiner Time: 11.25 seconds\n",
            "PyPDF2 Time: 4.02 seconds\n",
            "Processing: COPY_The_Continuum_Huntington_edited.pdf\n",
            "PyMuPDF Time: 1.64 seconds\n",
            "PDFMiner Time: 0.14 seconds\n",
            "PyPDF2 Time: 0.07 seconds\n",
            "Processing: COPY_SetTheoryPart1ofPart1.pdf\n",
            "PyMuPDF Time: 1.39 seconds\n",
            "PDFMiner Time: 0.22 seconds\n",
            "PyPDF2 Time: 0.03 seconds\n",
            "Processing: PDF_Set_Theory.pdf\n",
            "PyMuPDF Time: 1.47 seconds\n",
            "PDFMiner Time: 8.88 seconds\n",
            "PyPDF2 Time: 2.55 seconds\n",
            "Processing: PDF_Sets, Relations, Functions.pdf\n",
            "PyMuPDF Time: 0.24 seconds\n",
            "PDFMiner Time: 4.93 seconds\n",
            "PyPDF2 Time: 1.44 seconds\n",
            "Processing: PDF_SetTheoreticApproach.pdf\n",
            "PyMuPDF Time: 1.31 seconds\n",
            "PDFMiner Time: 10.09 seconds\n",
            "PyPDF2 Time: 3.81 seconds\n",
            "Processing: PDF_SetTheoryUnited.pdf\n",
            "PyMuPDF Time: 1.31 seconds\n",
            "PDFMiner Time: 20.59 seconds\n",
            "PyPDF2 Time: 7.33 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import difflib\n",
        "\n",
        "def compare_texts(text1, text2, max_length=1000):\n",
        "    \"\"\" Calculate the similarity score between shortened versions of two texts. \"\"\"\n",
        "    # Shorten texts to the first max_length characters\n",
        "    text1 = text1[:max_length]\n",
        "    text2 = text2[:max_length]\n",
        "    return difflib.SequenceMatcher(None, text1, text2).ratio()\n",
        "\n",
        "\n",
        "def read_text(file_path):\n",
        "    \"\"\" Read text file and return content. \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def process_book_folder(book_folder):\n",
        "    \"\"\" Process each book folder to compare text outputs from different libraries and check for empty files. \"\"\"\n",
        "    library_texts = {}\n",
        "    empty_files = []\n",
        "    for library_folder in os.listdir(book_folder):\n",
        "        full_library_path = os.path.join(book_folder, library_folder)\n",
        "        if os.path.isdir(full_library_path):\n",
        "            for file in os.listdir(full_library_path):\n",
        "                if file.endswith('.txt'):\n",
        "                    text_path = os.path.join(full_library_path, file)\n",
        "                    text_content = read_text(text_path)\n",
        "                    if not text_content.strip():  # Check if the text content is empty\n",
        "                        empty_files.append((library_folder, file))\n",
        "                    library_texts[library_folder] = text_content\n",
        "\n",
        "    # Report empty files\n",
        "    if empty_files:\n",
        "        print(f\"Empty text files found in {os.path.basename(book_folder)}:\")\n",
        "        for lib, file in empty_files:\n",
        "            print(f\"  Library: {lib}, File: {file}\")\n",
        "\n",
        "    # Compare texts from different libraries if not empty\n",
        "    library_names = list(library_texts.keys())\n",
        "    for i in range(len(library_names)):\n",
        "        for j in range(i + 1, len(library_names)):\n",
        "            lib1, lib2 = library_names[i], library_names[j]\n",
        "            if library_texts[lib1] and library_texts[lib2]:  # Only compare if both texts are non-empty\n",
        "                score = compare_texts(library_texts[lib1], library_texts[lib2])\n",
        "                print(f\"Similarity score between {lib1} and {lib2} for {os.path.basename(book_folder)}: {score:.2f}\")\n",
        "\n",
        "def main():\n",
        "    base_path = '/content/drive/MyDrive/🅰 Aleph - Capstone Project 2024/PDF to TXT books TEST'\n",
        "    for book_folder_name in os.listdir(base_path):\n",
        "        book_folder_path = os.path.join(base_path, book_folder_name)\n",
        "        if os.path.isdir(book_folder_path):\n",
        "            print(f\"Processing book: {book_folder_name}\")\n",
        "            process_book_folder(book_folder_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEg2Dy0zINZ7",
        "outputId": "449d65f4-141d-4807-a823-c02519aee433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing book: COPY_axiomatic-set-theory\n",
            "Similarity score between PyMuPDF and PDFMiner for COPY_axiomatic-set-theory: 0.88\n",
            "Similarity score between PyMuPDF and PyPDF2 for COPY_axiomatic-set-theory: 0.99\n",
            "Similarity score between PDFMiner and PyPDF2 for COPY_axiomatic-set-theory: 0.86\n",
            "Processing book: COPY_abstract_set_theory\n",
            "Similarity score between PyMuPDF and PDFMiner for COPY_abstract_set_theory: 0.66\n",
            "Similarity score between PyMuPDF and PyPDF2 for COPY_abstract_set_theory: 1.00\n",
            "Similarity score between PDFMiner and PyPDF2 for COPY_abstract_set_theory: 0.62\n",
            "Processing book: COPY_The_Continuum_Huntington_edited\n",
            "Empty text files found in COPY_The_Continuum_Huntington_edited:\n",
            "  Library: PyMuPDF, File: COPY_The_Continuum_Huntington_edited.txt\n",
            "  Library: PDFMiner, File: COPY_The_Continuum_Huntington_edited.txt\n",
            "  Library: PyPDF2, File: COPY_The_Continuum_Huntington_edited.txt\n",
            "Processing book: COPY_SetTheoryPart1ofPart1\n",
            "Empty text files found in COPY_SetTheoryPart1ofPart1:\n",
            "  Library: PyMuPDF, File: COPY_SetTheoryPart1ofPart1.txt\n",
            "  Library: PDFMiner, File: COPY_SetTheoryPart1ofPart1.txt\n",
            "  Library: PyPDF2, File: COPY_SetTheoryPart1ofPart1.txt\n",
            "Processing book: PDF_Set_Theory\n",
            "Similarity score between PyMuPDF and PDFMiner for PDF_Set_Theory: 0.68\n",
            "Similarity score between PyMuPDF and PyPDF2 for PDF_Set_Theory: 0.93\n",
            "Similarity score between PDFMiner and PyPDF2 for PDF_Set_Theory: 0.76\n",
            "Processing book: PDF_Sets, Relations, Functions\n",
            "Similarity score between PyMuPDF and PDFMiner for PDF_Sets, Relations, Functions: 0.98\n",
            "Similarity score between PyMuPDF and PyPDF2 for PDF_Sets, Relations, Functions: 0.98\n",
            "Similarity score between PDFMiner and PyPDF2 for PDF_Sets, Relations, Functions: 0.98\n",
            "Processing book: PDF_SetTheoreticApproach\n",
            "Similarity score between PyMuPDF and PDFMiner for PDF_SetTheoreticApproach: 0.92\n",
            "Similarity score between PyMuPDF and PyPDF2 for PDF_SetTheoreticApproach: 0.97\n",
            "Similarity score between PDFMiner and PyPDF2 for PDF_SetTheoreticApproach: 0.91\n",
            "Processing book: PDF_SetTheoryUnited\n",
            "Similarity score between PyMuPDF and PDFMiner for PDF_SetTheoryUnited: 0.44\n",
            "Similarity score between PyMuPDF and PyPDF2 for PDF_SetTheoryUnited: 0.34\n",
            "Similarity score between PDFMiner and PyPDF2 for PDF_SetTheoryUnited: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation\n",
        "\n",
        "Given your needs for both speed and reliable text extraction:\n",
        "\n",
        "- PyMuPDF appears to be the best overall choice due to its consistently fast processing times and generally high similarity scores compared to the other libraries. This makes it a strong candidate for handling a large number of documents quickly while still providing reliable output.\n",
        "\n",
        "- PyPDF2 could be considered as a secondary option, especially in cases where PyMuPDF might not provide satisfactory results. Its performance and accuracy are generally acceptable, though not as fast as PyMuPDF.\n",
        "\n",
        "- PDFMiner might be reserved for specific cases where you suspect that PyMuPDF and PyPDF2 are missing some text or when you need to extract text that relies heavily on the exact formatting preserved by PDFMiner. Despite its slower speed, it can sometimes handle complex PDF structures better."
      ],
      "metadata": {
        "id": "5WRnewneOebM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline of converting PDF books into txt format with PyMuPDF and Tesseract"
      ],
      "metadata": {
        "id": "nZmXvZWmSB-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tesseract\n",
        "!sudo apt update\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev\n",
        "\n",
        "# Install Python libraries\n",
        "!pip install pytesseract\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "MB5aKJVFOfDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fee509-a2d7-4d0e-e675-f472b3b21631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Connecting to security.ubuntu.com] [Waiting for headers] [Connecting to ppa\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\u001b[0m\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\u001b[33m\r0% [3 InRelease 12.7 kB/128 kB 10%] [Connecting to security.ubuntu.com (185.125\u001b[0m\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [973 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,664 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,409 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,258 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,591 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,125 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,994 kB]\n",
            "Fetched 13.4 MB in 2s (5,986 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (9,726 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 3,744 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.1 [582 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,744 kB in 0s (12.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121972 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hej7a1thTdYy",
        "outputId": "8e35fdf5-c1d3-477f-be18-17a134e83955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 0s (1,024 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 122105 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R1WnlASBoBke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "def pdf_to_text_tesseract(pdf_path):\n",
        "    \"\"\"\n",
        "    Convert a PDF file to text using Tesseract OCR and save output in a specific folder.\n",
        "    :param pdf_path: Path to the PDF file.\n",
        "    \"\"\"\n",
        "    # Extract book name and create output folder\n",
        "    book_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "    output_folder = f'/content/drive/My Drive/🅰 Aleph - Capstone Project 2024/PDF to TXT books TEST/TESSERACT_{book_name}'  # Customize the path as needed\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Convert PDF to list of images\n",
        "    pages = convert_from_path(pdf_path, dpi=300)  # Adjust DPI for better accuracy if needed\n",
        "\n",
        "    # Process each page with Tesseract OCR\n",
        "    for i, page in enumerate(pages):\n",
        "        text = pytesseract.image_to_string(page, lang='eng')  # Change lang if different language\n",
        "\n",
        "        # Save text to a file\n",
        "        output_file_path = os.path.join(output_folder, f'page_{i + 1}.txt')\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        print(f\"Processed and saved page {i + 1}\")\n",
        "\n",
        "# Example usage for two books\n",
        "book_paths = [\n",
        "    '/content/drive/MyDrive/🅰 Aleph - Capstone Project 2024/PDF to TXT books TEST/COPY_SetTheoryPart1ofPart1.pdf',\n",
        "    '/content/drive/MyDrive/🅰 Aleph - Capstone Project 2024/PDF to TXT books TEST/COPY_The_Continuum_Huntington_edited.pdf'\n",
        "]\n",
        "\n",
        "for book_path in book_paths:\n",
        "    pdf_to_text_tesseract(book_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTqgxk9fSvyz",
        "outputId": "803caee9-d2d3-4cc1-f510-2cd391251cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved page 1\n",
            "Processed and saved page 2\n",
            "Processed and saved page 3\n",
            "Processed and saved page 4\n",
            "Processed and saved page 5\n",
            "Processed and saved page 6\n",
            "Processed and saved page 7\n",
            "Processed and saved page 8\n",
            "Processed and saved page 9\n",
            "Processed and saved page 10\n",
            "Processed and saved page 11\n",
            "Processed and saved page 12\n",
            "Processed and saved page 13\n",
            "Processed and saved page 14\n",
            "Processed and saved page 15\n",
            "Processed and saved page 16\n",
            "Processed and saved page 17\n",
            "Processed and saved page 18\n",
            "Processed and saved page 19\n",
            "Processed and saved page 20\n",
            "Processed and saved page 21\n",
            "Processed and saved page 22\n",
            "Processed and saved page 23\n",
            "Processed and saved page 24\n",
            "Processed and saved page 25\n",
            "Processed and saved page 26\n",
            "Processed and saved page 27\n",
            "Processed and saved page 28\n",
            "Processed and saved page 29\n",
            "Processed and saved page 30\n",
            "Processed and saved page 31\n",
            "Processed and saved page 32\n",
            "Processed and saved page 33\n",
            "Processed and saved page 34\n",
            "Processed and saved page 35\n",
            "Processed and saved page 36\n",
            "Processed and saved page 37\n",
            "Processed and saved page 38\n",
            "Processed and saved page 39\n",
            "Processed and saved page 40\n",
            "Processed and saved page 41\n",
            "Processed and saved page 42\n",
            "Processed and saved page 43\n",
            "Processed and saved page 44\n",
            "Processed and saved page 45\n",
            "Processed and saved page 46\n",
            "Processed and saved page 47\n",
            "Processed and saved page 48\n",
            "Processed and saved page 49\n",
            "Processed and saved page 50\n",
            "Processed and saved page 51\n",
            "Processed and saved page 1\n",
            "Processed and saved page 2\n",
            "Processed and saved page 3\n",
            "Processed and saved page 4\n",
            "Processed and saved page 5\n",
            "Processed and saved page 6\n",
            "Processed and saved page 7\n",
            "Processed and saved page 8\n",
            "Processed and saved page 9\n",
            "Processed and saved page 10\n",
            "Processed and saved page 11\n",
            "Processed and saved page 12\n",
            "Processed and saved page 13\n",
            "Processed and saved page 14\n",
            "Processed and saved page 15\n",
            "Processed and saved page 16\n",
            "Processed and saved page 17\n",
            "Processed and saved page 18\n",
            "Processed and saved page 19\n",
            "Processed and saved page 20\n",
            "Processed and saved page 21\n",
            "Processed and saved page 22\n",
            "Processed and saved page 23\n",
            "Processed and saved page 24\n",
            "Processed and saved page 25\n",
            "Processed and saved page 26\n",
            "Processed and saved page 27\n",
            "Processed and saved page 28\n",
            "Processed and saved page 29\n",
            "Processed and saved page 30\n",
            "Processed and saved page 31\n",
            "Processed and saved page 32\n",
            "Processed and saved page 33\n",
            "Processed and saved page 34\n",
            "Processed and saved page 35\n",
            "Processed and saved page 36\n",
            "Processed and saved page 37\n",
            "Processed and saved page 38\n",
            "Processed and saved page 39\n",
            "Processed and saved page 40\n",
            "Processed and saved page 41\n",
            "Processed and saved page 42\n",
            "Processed and saved page 43\n",
            "Processed and saved page 44\n",
            "Processed and saved page 45\n",
            "Processed and saved page 46\n",
            "Processed and saved page 47\n",
            "Processed and saved page 48\n",
            "Processed and saved page 49\n",
            "Processed and saved page 50\n",
            "Processed and saved page 51\n",
            "Processed and saved page 52\n",
            "Processed and saved page 53\n",
            "Processed and saved page 54\n",
            "Processed and saved page 55\n",
            "Processed and saved page 56\n",
            "Processed and saved page 57\n",
            "Processed and saved page 58\n",
            "Processed and saved page 59\n",
            "Processed and saved page 60\n",
            "Processed and saved page 61\n",
            "Processed and saved page 62\n",
            "Processed and saved page 63\n",
            "Processed and saved page 64\n",
            "Processed and saved page 65\n",
            "Processed and saved page 66\n",
            "Processed and saved page 67\n",
            "Processed and saved page 68\n",
            "Processed and saved page 69\n",
            "Processed and saved page 70\n",
            "Processed and saved page 71\n",
            "Processed and saved page 72\n",
            "Processed and saved page 73\n",
            "Processed and saved page 74\n",
            "Processed and saved page 75\n",
            "Processed and saved page 76\n",
            "Processed and saved page 77\n",
            "Processed and saved page 78\n",
            "Processed and saved page 79\n",
            "Processed and saved page 80\n",
            "Processed and saved page 81\n",
            "Processed and saved page 82\n",
            "Processed and saved page 83\n",
            "Processed and saved page 84\n",
            "Processed and saved page 85\n",
            "Processed and saved page 86\n",
            "Processed and saved page 87\n",
            "Processed and saved page 88\n",
            "Processed and saved page 89\n",
            "Processed and saved page 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzdBbM6q3P43",
        "outputId": "acc1f3ba-d2a1-4514-e5af-14034f9e0998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install PyMuPDF\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract\n",
        "!apt-get install poppler-utils  # For pdf2image on Linux\n",
        "!apt-get install tesseract-ocr  # For Tesseract on Linux\n",
        "!pip install Pillow\n",
        "!pip install psutil\n",
        "!pip install tqdm\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import logging\n",
        "import gc\n",
        "import psutil\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "# Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Define the base directory where 'CS' and 'MATH' folders are located\n",
        "base_dir = '/content/drive/MyDrive/Capstone Project 2024-2025'\n",
        "\n",
        "cs_dir = os.path.join(base_dir, 'CS')\n",
        "math_dir = os.path.join(base_dir, 'MATH')\n",
        "\n",
        "# Output directory for the text files\n",
        "output_dir = os.path.join(base_dir, 'TextFiles')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the path for the log file\n",
        "log_file_path = os.path.join(base_dir, 'processing_logs.log')\n",
        "\n",
        "# Configure logging to write to a file and to the console\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(log_file_path),  # Log to file\n",
        "        logging.StreamHandler()              # Also log to console\n",
        "    ]\n",
        ")\n",
        "\n",
        "def memory_usage():\n",
        "    \"\"\"\n",
        "    Logs the current memory usage.\n",
        "    \"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    mem = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
        "    logging.info(f\"Current memory usage: {mem:.2f} MB\")\n",
        "\n",
        "def count_pdfs(directory):\n",
        "    \"\"\"\n",
        "    Counts the total number of PDF files in the directory and its subdirectories.\n",
        "    \"\"\"\n",
        "    pdf_count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        pdf_count += sum(1 for file in files if file.lower().endswith('.pdf'))\n",
        "    return pdf_count\n",
        "\n",
        "def extract_text_pymupdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from PDF using PyMuPDF (fitz).\n",
        "    Returns the extracted text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc.load_page(page_num)\n",
        "            text += page.get_text()\n",
        "            page = None  # Release page resource\n",
        "        doc.close()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting text with PyMuPDF from {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_pdf(pdf_path, txt_output_path, tesseract_pdfs):\n",
        "    \"\"\"\n",
        "    Process a single PDF file:\n",
        "    - Try to extract text using PyMuPDF.\n",
        "    - If no text is extracted, add the PDF to tesseract_pdfs list.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Processing PDF: {pdf_path}\")\n",
        "    # Try PyMuPDF first\n",
        "    text = extract_text_pymupdf(pdf_path)\n",
        "    if text.strip():\n",
        "        logging.info(f\"Text extracted using PyMuPDF from {pdf_path}\")\n",
        "        # Save the extracted text\n",
        "        os.makedirs(os.path.dirname(txt_output_path), exist_ok=True)\n",
        "        with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        logging.info(f\"Extracted text saved to {txt_output_path}\")\n",
        "    else:\n",
        "        logging.info(f\"No text extracted using PyMuPDF from {pdf_path}. Skipping Tesseract OCR for now.\")\n",
        "        # Add the PDF path to the list for later processing with Tesseract\n",
        "        tesseract_pdfs.append(pdf_path)\n",
        "        logging.info(f\"Added {pdf_path} to Tesseract processing list.\")\n",
        "\n",
        "    # Clean up\n",
        "    del text\n",
        "    gc.collect()\n",
        "\n",
        "def process_all_pdfs(base_input_dir, base_output_dir, tesseract_pdfs):\n",
        "    total_pdfs = count_pdfs(base_input_dir)\n",
        "    logging.info(f\"Total PDFs to process in {base_input_dir}: {total_pdfs}\")\n",
        "\n",
        "    processed_count = 0\n",
        "\n",
        "    # Use tqdm for a progress bar\n",
        "    for root, dirs, files in os.walk(base_input_dir):\n",
        "        pdf_files = [file for file in files if file.lower().endswith('.pdf')]\n",
        "        if pdf_files:\n",
        "            for file in tqdm(pdf_files, desc=f\"Processing PDFs in {root}\", unit='file'):\n",
        "                pdf_path = os.path.join(root, file)\n",
        "                # Construct the output text file path, mirroring the directory structure\n",
        "                relative_path = os.path.relpath(root, base_input_dir)\n",
        "                txt_output_dir = os.path.join(output_dir, relative_path)\n",
        "                txt_output_path = os.path.join(txt_output_dir, f\"{os.path.splitext(file)[0]}.txt\")\n",
        "                # Check if the text file already exists to avoid reprocessing\n",
        "                if os.path.exists(txt_output_path):\n",
        "                    logging.info(f\"Text file already exists for {pdf_path}. Skipping.\")\n",
        "                    processed_count += 1\n",
        "                    continue\n",
        "                # Process the PDF\n",
        "                process_pdf(pdf_path, txt_output_path, tesseract_pdfs)\n",
        "                processed_count += 1\n",
        "                # Monitor memory usage\n",
        "                memory_usage()\n",
        "                logging.info(f\"Processed {processed_count}/{total_pdfs} PDFs.\")\n",
        "\n",
        "# List to keep track of PDFs that need Tesseract OCR\n",
        "tesseract_pdfs = []\n",
        "\n",
        "# Process PDFs in the 'CS' folder\n",
        "logging.info(\"Starting processing of CS PDFs...\")\n",
        "process_all_pdfs(cs_dir, os.path.join(output_dir, 'CS'), tesseract_pdfs)\n",
        "\n",
        "# Process PDFs in the 'MATH' folder\n",
        "logging.info(\"Starting processing of MATH PDFs...\")\n",
        "process_all_pdfs(math_dir, os.path.join(output_dir, 'MATH'), tesseract_pdfs)\n",
        "\n",
        "# Save the list of PDFs that need Tesseract OCR for later processing\n",
        "tesseract_list_path = os.path.join(base_dir, 'tesseract_pdfs.txt')\n",
        "with open(tesseract_list_path, 'w', encoding='utf-8') as f:\n",
        "    for pdf in tesseract_pdfs:\n",
        "        f.write(f\"{pdf}\\n\")\n",
        "logging.info(f\"List of PDFs that need Tesseract OCR saved to {tesseract_list_path}\")\n",
        "\n",
        "# Processing PDFs with Tesseract OCR (to be run later when ready)\n",
        "def extract_text_tesseract(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from PDF using Tesseract OCR, processing one page at a time.\n",
        "    Returns the extracted text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        doc = fitz.open(pdf_path)\n",
        "        num_pages = len(doc)\n",
        "        doc.close()\n",
        "        for page_num in range(1, num_pages + 1):\n",
        "            images = convert_from_path(pdf_path, dpi=200, first_page=page_num, last_page=page_num)\n",
        "            for img in images:\n",
        "                # Use Tesseract to do OCR on the image\n",
        "                custom_oem_psm_config = r'--oem 1 --psm 3'\n",
        "                text += pytesseract.image_to_string(img, config=custom_oem_psm_config)\n",
        "                img.close()  # Close image to free memory\n",
        "                del img\n",
        "                gc.collect()\n",
        "            del images\n",
        "            gc.collect()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting text with Tesseract from {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_pdf_with_tesseract(pdf_path):\n",
        "    logging.info(f\"Processing PDF with Tesseract: {pdf_path}\")\n",
        "    text = extract_text_tesseract(pdf_path)\n",
        "    if text.strip():\n",
        "        logging.info(f\"Text extracted using Tesseract OCR from {pdf_path}\")\n",
        "        # Construct the output text file path, mirroring the directory structure\n",
        "        relative_path = ''\n",
        "        if pdf_path.startswith(cs_dir):\n",
        "            relative_path = os.path.relpath(os.path.dirname(pdf_path), cs_dir)\n",
        "            txt_output_dir = os.path.join(output_dir, 'CS', relative_path)\n",
        "        elif pdf_path.startswith(math_dir):\n",
        "            relative_path = os.path.relpath(os.path.dirname(pdf_path), math_dir)\n",
        "            txt_output_dir = os.path.join(output_dir, 'MATH', relative_path)\n",
        "        else:\n",
        "            logging.error(f\"PDF path {pdf_path} does not match CS or MATH directories.\")\n",
        "            return\n",
        "        txt_output_path = os.path.join(txt_output_dir, f\"{os.path.splitext(os.path.basename(pdf_path))[0]}.txt\")\n",
        "        # Save the extracted text\n",
        "        os.makedirs(txt_output_dir, exist_ok=True)\n",
        "        with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        logging.info(f\"Extracted text saved to {txt_output_path}\")\n",
        "    else:\n",
        "        logging.warning(f\"No text extracted from {pdf_path} using Tesseract OCR.\")\n",
        "\n",
        "    # Clean up\n",
        "    del text\n",
        "    gc.collect()\n",
        "\n",
        "# Load the list of PDFs that need Tesseract OCR\n",
        "tesseract_list_path = os.path.join(base_dir, 'tesseract_pdfs.txt')\n",
        "with open(tesseract_list_path, 'r', encoding='utf-8') as f:\n",
        "    tesseract_pdfs = [line.strip() for line in f.readlines()]\n",
        "logging.info(f\"Total PDFs to process with Tesseract OCR: {len(tesseract_pdfs)}\")\n",
        "\n",
        "# Process PDFs with Tesseract OCR\n",
        "logging.info(\"Starting Tesseract OCR processing...\")\n",
        "for pdf_path in tqdm(tesseract_pdfs, desc=\"Processing PDFs with Tesseract OCR\", unit='file'):\n",
        "    process_pdf_with_tesseract(pdf_path)\n",
        "    # Monitor memory usage\n",
        "    memory_usage()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxTkp37w3Gh0",
        "outputId": "833a8f84-b42b-43a3-b11e-a35dc009ed78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.14)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.0.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/Functional programming: 100%|██████████| 10/10 [00:00<00:00, 2610.67file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/Automata: 100%|██████████| 10/10 [00:00<00:00, 4252.56file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/Data Struct and Algs: 100%|██████████| 12/12 [00:00<00:00, 2533.05file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/Compiler: 100%|██████████| 11/11 [00:00<00:00, 33.07file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/Imperative programming: 100%|██████████| 11/11 [00:00<00:00, 2257.21file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/OOP: 100%|██████████| 10/10 [00:00<00:00, 2807.81file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/CS/OS: 100%|██████████| 10/10 [00:00<00:00, 3835.67file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Linear Algebra: 100%|██████████| 10/10 [00:00<00:00, 3823.78file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Combinatorics: 100%|██████████| 10/10 [00:00<00:00, 3800.57file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Set Theory: 100%|██████████| 15/15 [00:00<00:00, 69.53file/s] \n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Probability: 100%|██████████| 10/10 [00:00<00:00, 4234.53file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Calculus: 100%|██████████| 10/10 [00:00<00:00, 1269.31file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Logic: 100%|██████████| 10/10 [00:00<00:00, 2783.58file/s]\n",
            "Processing PDFs in /content/drive/MyDrive/Capstone Project 2024-2025/MATH/Abstract Algebra: 100%|██████████| 11/11 [00:00<00:00, 50.36file/s]\n",
            "Processing PDFs with Tesseract OCR: 100%|██████████| 5/5 [2:00:55<00:00, 1451.11s/file]\n"
          ]
        }
      ]
    }
  ]
}